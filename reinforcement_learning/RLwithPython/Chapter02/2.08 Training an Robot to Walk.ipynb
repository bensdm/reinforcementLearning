{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an agent to Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us learn how to train a robot to walk using Gym along with some fundamentals.\n",
    "The strategy is that reward X points will be given when the robot moves forward and if the\n",
    "robot fails to move then Y points will be reduced. So the robot will learn to walk in the\n",
    "event of maximizing the reward.\n",
    "\n",
    "First, we will import the library, then we will create a simulation instance by make\n",
    "function. \n",
    "\n",
    "\n",
    "Open AI Gym provides an environment called BipedalWalker-v2 for training\n",
    "robotic agents in simple terrain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('BipedalWalker-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then for each episode (Agent-Environment interaction between initial and final state), we\n",
    "will initialize the environment using reset method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "80 timesteps taken for the Episode\n",
      "68 timesteps taken for the Episode\n",
      "67 timesteps taken for the Episode\n",
      "63 timesteps taken for the Episode\n",
      "70 timesteps taken for the Episode\n",
      "102 timesteps taken for the Episode\n",
      "81 timesteps taken for the Episode\n",
      "70 timesteps taken for the Episode\n",
      "102 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "55 timesteps taken for the Episode\n",
      "54 timesteps taken for the Episode\n",
      "154 timesteps taken for the Episode\n",
      "33 timesteps taken for the Episode\n",
      "63 timesteps taken for the Episode\n",
      "82 timesteps taken for the Episode\n",
      "75 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "68 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "65 timesteps taken for the Episode\n",
      "67 timesteps taken for the Episode\n",
      "93 timesteps taken for the Episode\n",
      "53 timesteps taken for the Episode\n",
      "98 timesteps taken for the Episode\n",
      "54 timesteps taken for the Episode\n",
      "76 timesteps taken for the Episode\n",
      "89 timesteps taken for the Episode\n",
      "46 timesteps taken for the Episode\n",
      "46 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "72 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "104 timesteps taken for the Episode\n",
      "36 timesteps taken for the Episode\n",
      "58 timesteps taken for the Episode\n",
      "85 timesteps taken for the Episode\n",
      "72 timesteps taken for the Episode\n",
      "83 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "79 timesteps taken for the Episode\n",
      "151 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "72 timesteps taken for the Episode\n",
      "66 timesteps taken for the Episode\n",
      "88 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "68 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "96 timesteps taken for the Episode\n",
      "57 timesteps taken for the Episode\n",
      "73 timesteps taken for the Episode\n",
      "87 timesteps taken for the Episode\n",
      "50 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "68 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "59 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "52 timesteps taken for the Episode\n",
      "44 timesteps taken for the Episode\n",
      "125 timesteps taken for the Episode\n",
      "90 timesteps taken for the Episode\n",
      "64 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "89 timesteps taken for the Episode\n",
      "76 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "83 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "58 timesteps taken for the Episode\n",
      "119 timesteps taken for the Episode\n",
      "91 timesteps taken for the Episode\n",
      "95 timesteps taken for the Episode\n",
      "106 timesteps taken for the Episode\n",
      "87 timesteps taken for the Episode\n",
      "71 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "46 timesteps taken for the Episode\n",
      "93 timesteps taken for the Episode\n",
      "55 timesteps taken for the Episode\n",
      "146 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "94 timesteps taken for the Episode\n",
      "124 timesteps taken for the Episode\n",
      "98 timesteps taken for the Episode\n",
      "61 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n",
      "85 timesteps taken for the Episode\n",
      "62 timesteps taken for the Episode\n",
      "111 timesteps taken for the Episode\n",
      "1600 timesteps taken for the Episode\n"
     ]
    }
   ],
   "source": [
    "for episode in range(100):\n",
    "    observation = env.reset()\n",
    "    \n",
    "    # Render the environment on each step \n",
    "    for i in range(10000):\n",
    "        env.render()\n",
    "            \n",
    "        # we choose action by sampling random action from environment's action space. Every environment has\n",
    "        # some action space which contains the all possible valid actions and observations,\n",
    "        \n",
    "        action = env.action_space.sample()\n",
    "    \n",
    "        # Then for each step, we will record the observation, reward, done, info\n",
    "        observation, reward, done, info = env.step(action)\n",
    "    \n",
    "   # When done is true, we print the time steps taken for the episode and break the current episode.\n",
    "        if done:\n",
    "            print(\"{} timesteps taken for the Episode\".format(i+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent will learn by trail and error and over a period of time it starts selecting actions which gives the\n",
    "maximum rewards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
